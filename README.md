
# ğŸ“Š Customer Churn Prediction using Machine Learning

---

## ğŸ” Project Overview  
This project aims to predict customer churn using a real-world telecom dataset. By identifying customers likely to cancel their subscription, businesses can proactively improve retention and reduce revenue loss.

---

## âœ… Problem Statement  
Customer churn significantly affects subscription-based businesses. The objective is to use customer demographic and usage data to train a machine learning model that accurately predicts churn behavior.

---

## ğŸ’¾ Dataset  
- **Source:** [Telco Customer Churn Dataset â€“ Kaggle](https://www.kaggle.com/datasets/blastchar/telco-customer-churn)  
- **Size:** 7,043 rows Ã— 21 columns  
- **Target Variable:** `Churn` (Yes/No)  
- **Features:** Customer demographics, services subscribed, billing, and tenure details

---

## ğŸ§  Feature Engineering  
To improve prediction accuracy, the following features were engineered:

- **AvgChargesPerMonth:** TotalCharges / Tenure  
- **num_services_subscribed:** Number of value-added services (e.g., OnlineSecurity, DeviceProtection)  
- **hasStreaming:** Binary flag for streaming services (TV or movies)

---

## âš–ï¸ Handling Imbalanced Data  
The original dataset had a class imbalance with fewer churners. We applied **SMOTE (Synthetic Minority Over-sampling Technique)** to generate synthetic samples for the minority class, resulting in a significant improvement in recall.

---

## ğŸ› ï¸ Tools & Technologies  

- **Environment:** Python (Google Colab)  
- **Libraries:**  
  - `pandas`, `numpy` â€“ Data wrangling  
  - `matplotlib`, `seaborn` â€“ Visualization  
  - `scikit-learn` â€“ Modeling, preprocessing, evaluation  
  - `imblearn` â€“ SMOTE  
  - `joblib` â€“ Saving/loading models  
  - `GridSearchCV` â€“ Hyperparameter tuning

---

## ğŸ§ª Machine Learning Models Used  

| Model | Description |
|-------|-------------|
| **Logistic Regression** | Used as a baseline model, then tuned and enhanced with SMOTE |
| **Random Forest Classifier** | Ensemble model capturing non-linear relationships |

---

## ğŸ“ˆ Evaluation Metrics  

- **Accuracy**  
- **Recall** (especially important for churn detection)  
- **Precision**  
- **F1-Score**  
- **Confusion Matrix**  
- **Cross-Validation Scores**

---

## ğŸ“Š Logistic Regression Comparison  

| Model Version           | Accuracy | Recall (Churn) | Precision (Churn) | F1-Score (Churn) |
|------------------------|----------|----------------|-------------------|------------------|
| Base Logistic Regression | 0.79     | 0.52           | 0.62              | 0.56             |
| Tuned (GridSearchCV)     | 0.79     | 0.52           | 0.63              | 0.57             |
| **SMOTE-Based**             | 0.74     | **0.80**           | 0.50              | **0.62**             |

---

## âœ… Final Model Selected  
**SMOTE-Based Logistic Regression**  
Chosen for its **high recall (80%)**, ensuring that more churners are identified even at the cost of lower precision â€” a tradeoff often acceptable in churn prediction scenarios.

---

## ğŸ“ Folder Structure  

```
Customer-Churn-Prediction/
â”‚
â”œâ”€â”€ Customer_Churn_Prediction.ipynb      # Main notebook
â”œâ”€â”€ README.md                   
â”œâ”€â”€ WA_Fn-UseC_-Telco-Customer-Churn.csv  # Dataset
â”‚
â”œâ”€â”€ models/                     # Saved model files
â”‚   â”œâ”€â”€ best_logistic_model.pkl
â”‚   â””â”€â”€ scaler.pkl
â”‚
â””â”€â”€ images/                     # Optional plots and charts
```

---

## ğŸ“ Models Folder  

- **best_logistic_model.pkl** â€“ Final logistic regression model (SMOTE-enhanced)  
- **scaler.pkl** â€“ StandardScaler used on numeric data before model training  

You can load them like this:

```python
import joblib

# Load trained model and scaler
model = joblib.load('models/best_logistic_model.pkl')
scaler = joblib.load('models/scaler.pkl')
```

---

## ğŸš€ How to Run  

1. Download the dataset from [Kaggle](https://www.kaggle.com/datasets/blastchar/telco-customer-churn)  
2. Upload it to Google Colab or run locally  
3. Open `churn_prediction.ipynb`  
4. Execute each cell step by step to:
   - Preprocess the data  
   - Engineer features  
   - Train & evaluate models  
   - Save the best-performing model  

---

## ğŸ“Œ Future Work  

- ğŸš€ **Model Deployment** using **Streamlit** or **Flask**  
- ğŸ“Š Create a **dashboard** to monitor churn predictions in real time  
- ğŸ” Use **SHAP** for explainable AI and feature impact interpretation  
- ğŸ¤– Try **stacked ensembles** for even better prediction accuracy  

---

## ğŸ‘©â€ğŸ’» Author  

**Nayomi Thilakarathna**  
A fresher in Data Analytics passionate about machine learning, insights generation, and solving real-world business problems.  

---

ğŸŒŸ If you found this project useful, please consider giving it a â­ on GitHub!
